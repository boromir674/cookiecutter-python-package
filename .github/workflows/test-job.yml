name: "Test Job"

on:
  workflow_call:
    inputs:
      typecheck_policy:
        required: false
        type: string
        default: "1"
        description: "0 = Off, 1 = On, 2 = Allow Fail"

      # JOB_MATRIX
      job_matrix:
        required: false
        type: string
        default: "{\"platform\": [\"ubuntu-latest\"], \"python-version\": [\"3.10\"]}"

      # POLICY
      run_policy:
        required: false
        type: string
        default: '1'
        description: "0 = Off, 1 = On"

      # TODO support this feature
      # # BUILD_INSTALLATION
      # build_installation:
      #   required: false
      #   type: string
      #   default: 'edit sdist wheel'
      #   description: "Code Installation Modes, for running Tests"

      # ARTIFACT NAME
      artifact_name:
        required: false
        type: string
        default: 'dist'
        description: "CI Artifact Name (id / alias) for uploading Distros, such as files .tar.gz, .whl(s)"

    ### OUTPUTS ###
    # Map the workflow outputs to job outputs
    outputs:
      PEP_VERSION:
        description: "PEP version of the wheel file"
        value: ${{ jobs.test_suite.outputs.PEP_VERSION }}
      # COVERAGE_ARTIFACT:
      #   description: "CI Artifact Name (id / alias) of uploaded Coverage XML"
      #   value: ${{ jobs.test_build.outputs.COVERAGE_ARTIFACT }}

jobs:
  # RUN TEST SUITE ON ALL PLATFORMS
  test_suite:
    runs-on: ${{ matrix.platform }}
    if: always() && inputs.run_policy != 0
    strategy:
      matrix: ${{fromJSON(inputs.job_matrix)}}
      fail-fast: false
    outputs:
      PEP_VERSION: ${{ steps.extract_wheel_info.outputs.PEP_VERSION }}
      # COVERAGE_ARTIFACT: ${{ steps.set_coverage_artifact.outputs.COVERAGE_ARTIFACT }}
    env:
      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      WHEELS_PIP_DIR: "wheels-pip"
        # --cov-report=html:{envdir}/htmlcov \
      PYTEST_ARGS: >
        -ra --cov --cov-report=term-missing \
        --cov-context=test \
        --cov-report=xml:coverage.{envname}.xml \
        -n auto tests
      # log deletion post hook fails on windows, due to permission error! (other process is using the file, so removing is denied)
      # windows spawn multiple processes, so log deletion is not possible, even when running 1 Single Unit Test
      BUG_LOG_DEL_WIN: 'permission_error'

      # Dynamic command for 'Virtualenv activation' script
      VENV_ACTIVATE: ${{ matrix.platform == 'windows-latest' && 'Scripts/activate' || 'bin/activate' }}
    steps:
      - run: 'echo "OS: ${{ matrix.platform }}, Python: ${{ matrix.python-version }}"'

      # Setup Python
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}

      - uses: actions/checkout@v4

      - name: Install uv
        if: matrix.platform != 'windows-latest'
        run: curl -LsSf https://astral.sh/uv/install.sh | sh

      - name: Install uv
        if: matrix.platform == 'windows-latest'
        uses: astral-sh/setup-uv@v5
        with:
          version: "latest"

      # ### Sanity Check that folder is Compatible for Python Distro / Build ###
      # - run: uvx pyroma --directory .

      # # TYPE CHECKING with MYPY
      # - name: Do Type Checking
      #   if: matrix.platform != 'windows-latest'
      #   env:
      #     PKG: src/cookiecutter_python  # for DRYness
      #     MYPYPATH: src/stubs/  # REQUIRED for mypy to find our custom stubs
      #   shell: bash
      #   run: |
      #     uv export --no-emit-project --no-dev --extra typing --frozen --format requirements-txt -o requirements.txt
      #     uv venv
      #     uv pip install -r requirements.txt

      #     # mypy does not like, by default, multiple conftest.py (ses pytest) files
      #     # so we trick mypy into believing that tests is a package, because this way
      #     # pytest can distinguish between our 2 conftest.py files

      #     # create empty __init__.py in tests, temporarily
      #     touch tests/__init__.py

      #     echo "[INFO] Running mypy for type checking"

      #     uv run mypy --show-error-codes \
      #     --exclude tests/data \
      #     "${PKG}/hooks" \
      #     "${PKG}/backend" "${PKG}/handle" \
      #     "${PKG}/utils.py" "${PKG}/exceptions.py" \
      #     "${PKG}/cli.py" "${PKG}/cli_handlers.py" \
      #     "${PKG}/__main__.py" "${PKG}/__init__.py"

      #   # TODO start typechecking tests
      #   # TODO add the --check-untyped-defs flag

      # # delete temporarily created empty __init__.py in tests
      # - if: matrix.platform != 'windows-latest' && always()
      #   run: rm tests/__init__.py

      ### IF v*-rc tag pushed: update sources sem ver with -rc suffix ###
      - name: "Update Source Sem Ver with Release Candidate *-rc' suffix"
        if: ${{ startsWith(github.event.ref, 'refs/tags/v') && contains(github.event.ref, '-rc') }}
        shell: bash
        run: |
          # Extract PROD Sem Ver
          VERSION_SOURCE_OF_TRUTH='src/cookiecutter_python/__init__.py'

          REGEX='^[[:space:]]*__version__[[:space:]]*=[[:space:]]*["'\'']([0-9]+)\.([0-9]+)\.([0-9]+)["'\'']'

          SEMVER="$(grep -E -o "${REGEX}" "${VERSION_SOURCE_OF_TRUTH}" | sed -E "s/${REGEX}/\1.\2.\3/")"

          # Derive RC Sem Ver
          RC_SEMVER="${SEMVER}-rc"

          ## Set Source Sem Ver to Release Candidate Sem Ver ##
          sh ./scripts/distro-sem-ver-bump.sh "${RC_SEMVER}"

      # UV Export Prod + Test Dependencies (without package)
      - name: "Export exact 'Prod + Test' Dependencies in requirements.txt format"
        run: uv export --no-emit-project --no-dev --extra test --frozen --format requirements-txt -o prod+test.txt


      ######## PHASE 1: INSTALL CODE AND RUN SANITY CHECKS ########

      # 1. CREATE VENV and INSTALL 'Prod + Test' Dependencies
      - name: Create venv with exact 'Prod + Test' Dependencies
        shell: bash
        run: |
          uv venv venv-edit
          . venv-edit/${{ env.VENV_ACTIVATE }}
          uv pip install --no-deps -r prod+test.txt
      
      # 2. INSTALL Package in 'edit' mode
      - name: Install Package in 'edit' mode inside venv
        shell: bash
        run: |
          . venv-edit/${{ env.VENV_ACTIVATE }}
          uv pip install --no-deps -e .

      # 3. Test Mode 1: Run Test Suite against code
      - name: 'Run Test Suite against the Package code'
        shell: bash
        env:
          COVERAGE_FILE: '.coverage.edit'
        run: |
          . venv-edit/${{ env.VENV_ACTIVATE }}

          # pytest ${{ env.PYTEST_ARGS }}
          pytest -ra --cov --cov-report=term-missing \
            --cov-context=test \
            --cov-report=xml:coverage.test-edit.xml \
            -n auto tests


      ######## PHASE 2: BUILD WHEEL AND SDIST DISTRIBUTIONS FROM CODE ########
      # UV BUILD: Build Package Wheel and Sdist Distros: .whl and .tar.gz files
      - name: 'Build Package Wheel/Sdist distros, using uv and poetry.core.masonry.api'
        shell: bash
        id: uv_build
        run: |
          set -o pipefail
          uv build --out-dir dist . 2>&1 | tee test_output.log

      - name: Extract Package PEP Version from Wheel
        id: extract_wheel_info
        shell: bash
        run: |
          # Extract PEP version from wheel file name
          WHEEL_FILE=$(ls dist/cookiecutter_python-*.whl)

          # extract file name from wheel file
          WHEEL_NAME="$(basename $WHEEL_FILE)"

          echo "WHEEL_NAME=$WHEEL_NAME" >> $GITHUB_ENV

          # extract pep version from wheel file name, supporting patterns such as below:
          # - '1.15.0rc0' from 'cookiecutter_python-1.15.0rc0-py3-none-any.whl'
          # - '1.2.12' from 'cookiecutter_python-1.2.12-py3-none-any.whl'
          # - '1.2.12' from 'cookiecutter_python-1.2.12-cp3-abi3-any.whl'
          # - '3.0.7' from 'cookiecutter_python-3.0.7-jy3-none-any.whl'
          # - '8.9.37dev0' from 'cookiecutter_python-8-9-37dev0-jy3-none-win32.whl'
          # - '8.9.37dev0' from 'cookiecutter_python-8-9-37dev0-jy3-none-linux_i386.whl'

          PEP_VERSION=$(echo $WHEEL_NAME | cut -d'-' -f2 | sed 's/-/./g')
          echo "PEP_VERSION=$PEP_VERSION" >> $GITHUB_OUTPUT

          echo "[INFO] Extracted PEP version: $PEP_VERSION"
          ls -l "${WHEEL_FILE}"

      - name: Show dist folder
        shell: bash
        run: ls -la dist/


      ######## PHASE 3: VERIFY PACKAGE AND METADATA ARE VALID ########
      - run: mkdir verification
      - name: Verify packaged Wheel/Sdist Distros are valid according to python standards
        shell: bash
        working-directory: verification
        run: |
          uv venv check-env
          . check-env/${{ env.VENV_ACTIVATE }}
          uv pip install poetry-core pyroma 'twine >=5.0.0, <6.0.0'
          # --active

          # Check .tar.gz file using 'pyroma' command
          echo "[INFO] Running pyroma on the sdist"
          pyroma --file "$(ls ../dist/*.tar.gz)"

          # Check both .whl and .tar.gz files using 'twine check' command
          echo "[INFO] Running twine check on the sdist and wheel"
          python -m twine check ../dist/*


      ######## PHASE 4: INSTALL WHEELS AND RUN SANITY CHECKS ########

      # 1. Build All Wheels, install and Test
      - name: Build Wheels of 'Prod + Test' Dependencies
        run: pip wheel --wheel-dir dist-wheels -r prod+test.txt

      - name: Remove Package Wheel from dist-wheels
        # NOTE: this assumes only one Universal Wheel (ie pure python code) is produced by the build
        id: module_wheel_path
        shell: bash
        run: |
          MODULE_WHEEL_PATH="$(ls dist-wheels/cookiecutter_python-${PEP_VERSION}*.whl)"
          rm "${MODULE_WHEEL_PATH}"

      # 2. 
      - name: Install Package and prod+test Wheels
        shell: bash
        run: |
          uv venv venv-wheels
          . venv-wheels/${{ env.VENV_ACTIVATE }}

          uv pip install --no-deps dist-wheels/*.whl
          uv pip install --no-deps dist/*.whl
      
      # 3. Run Tests
      - name: 'Run Test Suite against the Package Wheel and prod+test wheels'
        shell: bash
        env:
          COVERAGE_FILE: '.coverage.wheels'
        run: |
          . venv-wheels/${{ env.VENV_ACTIVATE }}
          pytest -ra --cov --cov-report=term-missing \
            --cov-report=html:test-wheels/htmlcov --cov-context=test \
            --cov-report=xml:coverage.test-wheels.xml \
            -n auto tests


      ## Code Coverage ## TODO; enable combine by moving each .coverage file to other dir to avoid override of subsequent coverage invocations with pytest
      - name: "Combine Coverage (dev, sdist, wheel) & make Reports"
        env:
          COVERAGE_FILE: .coverage
          OUTPUT_XML: coverage-${{ matrix.platform }}-${{ matrix.python-version }}.xml
        shell: bash
        run: |
          uv venv cov-env
          . cov-env/${{ env.VENV_ACTIVATE }}
          uv pip install 'coverage[toml] >= 5.1' 'diff_cover >=6'

          echo '[INFO] Running coverage'
          coverage combine --keep
          coverage report --skip-covered --show-missing -i
          coverage xml -o ./${{ env.OUTPUT_XML }} -i
          # uv run coverage html -d ./htmlcov -i

      - name: "Upload Test Coverage as Artifacts"
        uses: actions/upload-artifact@v4
        with:
        # TODO: implement mechanism for uploading test reports on separate artifact names. then codecov host upload job should be able somehow to get all of them. then change below from true to false
          overwrite: false
          name: coverage-${{ matrix.platform }}-${{ matrix.python-version }}.xml
          path: coverage-${{ matrix.platform }}-${{ matrix.python-version }}.xml
          if-no-files-found: error

      - name: Upload Source & Wheel distributions as Artefacts
        if: always()  # TODO add condition on uv_build step succeeds
        uses: actions/upload-artifact@v4
        with:
          name: dist-${{ matrix.platform }}-${{ matrix.python-version }}
          path: dist
          if-no-files-found: error
