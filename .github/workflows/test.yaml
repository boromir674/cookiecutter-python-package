name: CI/CD Pipeline
# Continuous Integration / Continuous Delivery

# Triggers on all branches and tags starting with v

# Full Job Matrix for Stress Testing is activated on 'master', 'dev' and tags
## We Test factoring Platforms and Python versions

# For other branches only one Job is spawned for Running (Unit) Tests

# PyPI publish on v* tags on 'master' branch
# Test PyPI publish on v* 'pre-release' tags on 'release' branch

# Dockerhub publish on all branches and tags

on:
  push:
    branches:
      - "*"
    tags:
      - v*

env:
  # Job Matrix as an env var !
  # FULL_MATRIX_STRATEGY: "{\"platform\": [\"ubuntu-latest\", \"macos-latest\", \"windows-latest\"], \"python-version\": [\"3.7\", \"3.8\", \"3.9\", \"3.10\", \"3.11\"]}"

  # on Ubuntu Latest with Python 3.6, we encounter below error:
  
  # Version 3.6 was not found in the local cache
  # Error: The version '3.6' with architecture 'x64' was not found for Ubuntu 22.04.
  # The list of all available versions can be found here: https://raw.githubusercontent.com/actions/python-versions/main/versions-manifest.json

  # so for now we skip 3.6 on Ubuntu Latest
  FULL_MATRIX_STRATEGY: "{\"platform\": [\"macos-latest\", \"windows-latest\"], \"python-version\": [\"3.6\"]}"


  UBUNTU_PY310_STRATEGY: "{\"platform\":[\"ubuntu-latest\"], \"python-version\":[\"3.10\"]}"
  TEST_STRATEGY: "{\"platform\":[\"ubuntu-latest\", \"macos-latest\", \"windows-latest\"], \"python-version\":[\"3.9\"]}"

  ##### JOB ON/OFF SWITCHES #####
  RUN_UNIT_TESTS: "true"
  RUN_LINT_CHECKS: "true"
  DOCKER_JOB_ON: "true"
  PUBLISH_ON_PYPI: "true"
  DRAW_DEPENDENCIES: "true"
  ###############################

  ### DOCKER Job Policy ####
  # Override Docker Policy-dependent decision-making and
  # Accept any ALL (branch/build) to Publish to Dockerhub
  # if true, it will push image and ignore DOCKER_JOB_POLICY
  ALWAYS_BUILD_N_PUBLSIH_DOCKER: "false"

  DOCKER_JOB_POLICY: "CDeployment"
  # - CDeployment : Builds and Publishes only if Tests ran and passed
  # - CDelivery   : Builds and Publishes if Tests Passed or if Tests were Skipped
  ############################

  #### STATIC CODE ANALYSIS Job ####
  ## Python Runtime version to set the Job runner with ##
  STATIC_ANALYSIS_PY: "3.10"
  ## Pylint Minimum Acceptance Rating/Score ##
  PYLINT_SCORE_THRESHOLD: "8.2"
  ##########################

jobs:
  # we use the below to read the workflow env vars and be able to use in "- if:" Job conditionals
  # now we can do -> if: ${{ needs.set_github_outputs.outputs.TESTS_ENABLED == 'true' }}
  # github does not have a way to simply do "- if: ${{ env.RUN_UNIT_TESTS == 'true' }} " !!
  set_github_outputs:
    name: Read Workflow Env Section Vars and set Github Outputs
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.pass-env-to-output.outputs.matrix }}
      TESTS_ENABLED: ${{ steps.pass-env-to-output.outputs.TESTS_ENABLED }}
      DRAW_DEPS_SVG_GRAPHS: ${{ steps.pass-env-to-output.outputs.DRAW_DEPS_SVG_GRAPHS }}
      RUN_LINT: ${{ steps.pass-env-to-output.outputs.RUN_LINT }}
      PUBLISH_ON_PYPI: ${{ steps.pass-env-to-output.outputs.PUBLISH_ON_PYPI }}
    steps:
      - name: Pass 'env' section variables to GITHUB_OUTPUT
        id: pass-env-to-output
        run: |
          # set the matrix strategy to Full Matrix Stress Test if on master/main or stress-test branch or any tag
          BRANCH_NAME=${GITHUB_REF_NAME}
          if [[ $BRANCH_NAME == "master" || $BRANCH_NAME == "main" || $BRANCH_NAME == "stress-test" || $GITHUB_REF == refs/tags/* ]]; then
            echo "matrix=$FULL_MATRIX_STRATEGY" >> $GITHUB_OUTPUT
          else
            echo "matrix=$UBUNTU_PY310_STRATEGY" >> $GITHUB_OUTPUT
          fi
          echo "TESTS_ENABLED=$RUN_UNIT_TESTS" >> $GITHUB_OUTPUT
          echo "RUN_LINT=$RUN_LINT_CHECKS" >> $GITHUB_OUTPUT
          echo "PUBLISH_ON_PYPI=$PUBLISH_ON_PYPI" >> $GITHUB_OUTPUT
          echo "DRAW_DEPS_SVG_GRAPHS=$DRAW_DEPENDENCIES" >> $GITHUB_OUTPUT

# RUN TEST SUITE ON ALL PLATFORMS
  test_suite:
    runs-on: ${{ matrix.platform }}
    needs: set_github_outputs
    if: ${{ needs.set_github_outputs.outputs.TESTS_ENABLED == 'true' }}
    strategy:
      matrix: ${{fromJSON(needs.set_github_outputs.outputs.matrix)}}
    outputs:
      SEMVER_PIP_FORMAT: ${{ steps.parse_version.outputs.SEMVER_PIP_FORMAT }}
    steps:
    - run: echo "Platform -> ${{ matrix.platform }} , Python -> ${{ matrix.python-version }}"
    - uses: actions/checkout@v3
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    - run: python -m pip install --upgrade pip && python -m pip install tox==3.28 tox-gh-actions

    - name: Do Type Checking
      run: tox -e type -vv -s false

    - name: Parse package version from __init__.py to assist building
      shell: bash
      id: parse_version
      run: |
        PARSER="src/cookiecutter_python/{{ cookiecutter.project_slug }}/scripts/parse_version.py"
        PARSED_VERSION=$(python "${PARSER}")
        # transform version (ie 1.7.4-rc.1) to match the name of the wheel produced (ie 1.7.4rc1)
        WHEEL_VERSION=$(echo $PARSED_VERSION | sed -E 's/([^.]*)\.([^.]*)\.([^-]*)-(rc)\.?(.*)/\1.\2.\3\4\5/')
        # manually append the 0 to index the release candidate
        # we account for wheel building that automatically does the above
        last_two=${WHEEL_VERSION: -2}
        if [[ $last_two == "rc" ]]; then
          WHEEL_VERSION="${WHEEL_VERSION}0"
        fi
        echo "==== $PARSED_VERSION  -->  $WHEEL_VERSION"
        echo "PKG_VERSION=$WHEEL_VERSION" >> $GITHUB_ENV  # to be used in the next step
        echo "SEMVER_PIP_FORMAT=$WHEEL_VERSION" >> $GITHUB_OUTPUT  # to be used in other jobs
    - name: Run Unit Tests
      run: tox -vv -s false
      env:
        PLATFORM: ${{ matrix.platform }}
    - name: "Combine Coverage (dev, sdist, wheel) & make Reports"
      run: tox -e coverage --sitepackages -vv -s false

    - name: Rename Coverage Files
      shell: bash
      run: |
        mv ./.tox/coverage.xml ./coverage-${{ matrix.platform }}-${{ matrix.python-version }}.xml
    - name: "Upload Test Coverage as Artifacts"
      uses: actions/upload-artifact@v3
      with:
        name: all_coverage_raw
        path: coverage-${{ matrix.platform }}-${{ matrix.python-version }}.xml
        if-no-files-found: error
    - name: Check for compliance with Python Best Practices
      shell: bash
      run: |
        DIST_DIR=dist
        echo "DIST_DIR=dist" >> $GITHUB_ENV
        mkdir ${DIST_DIR}
        mv ".tox/${DIST_DIR}/cookiecutter_python-${PKG_VERSION}.tar.gz" "${DIST_DIR}"
        mv ".tox/${DIST_DIR}/cookiecutter_python-${PKG_VERSION}-py3-none-any.whl" "${DIST_DIR}"
        tox -e check -vv -s false
    - name: Install documentation test dependencies
      if: ${{ matrix.platform == 'macos-latest' && matrix.python-version != '3.6' }}
      run: brew install enchant
    - name: Run Documentation Tests
      if: ${{ matrix.platform == 'ubuntu-latest' || matrix.python-version  != '3.6' }}
      run: tox -e docs --sitepackages -vv -s false
    - name: Upload Source & Wheel distributions as Artefacts
      uses: actions/upload-artifact@v3
      with:
        name: dist-${{ matrix.platform }}-${{ matrix.python-version }}
        path: ${{ env.DIST_DIR }}
        if-no-files-found: error

  codecov_coverage_host:
    runs-on: ubuntu-latest
    needs: test_suite
    steps:
    - uses: actions/checkout@v3
    - name: Get Codecov binary
      run: |
        curl -Os https://uploader.codecov.io/latest/linux/codecov
        chmod +x codecov
    - name: Download Raw Coverage Data Artefacts
      uses: actions/download-artifact@v3
      with:
        name: all_coverage_raw
    - name: Upload Coverage Reports to Codecov
      run: |
        for file in coverage*.xml; do
          OS_NAME=$(echo $file | sed -E "s/coverage-(\w\+)-/\1/")
          PY_VERSION=$(echo $file | sed -E "s/coverage-\w\+-(\d\.)\+/\1/")
          ./codecov -f $file -e "OS=$OS_NAME,PYTHON=$PY_VERSION" --flags unittests --verbose
          echo "Sent to Codecov: $file !"
        done

## AUTOMATED DOCKER BUILD and PUBLISH ON DOCKERHUB ##
  read_docker_settings:
    runs-on: ubuntu-latest
    outputs:
      CASE_POLICY: ${{ steps.derive_docker_policy.outputs.CASE_POLICY }}
    steps:
      - run: |
          if [[ $DOCKER_JOB_ON == "true" ]]; then
            if [[ $ALWAYS_BUILD_N_PUBLSIH_DOCKER == "true" ]]; then
              DOCKER_POLICY=1
            elif [[ $DOCKER_JOB_POLICY == "CDeployment" ]]; then
              DOCKER_POLICY=2
            elif [[ $DOCKER_JOB_POLICY == "CDelivery" ]]; then
              DOCKER_POLICY=3
            fi
          else
            DOCKER_POLICY=0
          fi
          echo "CASE_POLICY=$DOCKER_POLICY" >> $GITHUB_ENV

      - run: echo "CASE_POLICY=$CASE_POLICY" >> $GITHUB_OUTPUT
        id: derive_docker_policy

# DOCKER BUILD AND PUBLISH ON DOCKERHUB
  docker_build:
    needs: [read_docker_settings, test_suite]
    uses: boromir674/automated-workflows/.github/workflows/docker.yml@v1.1.0
    if: always()
    with:
      acceptance_policy: ${{ needs.read_docker_settings.outputs.CASE_POLICY }}
      image_slug: "generate-python"
      # target_stage: "some_stage_alias"  # no stage, means no `--target` flag, on build
      tests_pass: ${{ needs.test_suite.result == 'success' }}
      tests_run: ${{ !contains(fromJSON('["skipped", "cancelled"]'), needs.test_suite.result) }}
      DOCKER_USER: ${{ vars.DOCKER_USER }}
    secrets:
      DOCKER_PASSWORD: ${{ secrets.DOCKER_PASSWORD }}

  ## JOB: Signal for Automated PyPI Upload ##
  check_which_git_branch_we_are_on:
    runs-on: ubuntu-latest
    needs: set_github_outputs
    if: ${{ startsWith(github.event.ref, 'refs/tags/v') && needs.set_github_outputs.outputs.PUBLISH_ON_PYPI == 'true' }}
    outputs:
      ENVIRONMENT_NAME: ${{ steps.set_environment_name.outputs.ENVIRONMENT_NAME }}
      AUTOMATED_DEPLOY: ${{ steps.set_environment_name.outputs.AUTOMATED_DEPLOY }}

    # Signals only if all below are True:
    #  - PyPI Job Switch is ON
    #  - Workflow Event is a 'v*' Tag (e.g. v1.0.0, v-test)
    #  - Tag is tagging a commit on either the 'master' or 'release' Branch
    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0
      - uses: rickstaa/action-contains-tag@v1
        id: main_contains_tag
        with:
          reference: "master"
          tag: "${{ github.ref }}"
      - run: echo "ON_MAIN_BRANCH=${{ steps.main_contains_tag.outputs.retval }}" >> $GITHUB_OUTPUT
      - uses: rickstaa/action-contains-tag@v1
        id: release_contains_tag
        with:
          reference: "release"
          tag: "${{ github.ref }}"
      - run: echo "ON_RELEASE_BRANCH=${{ steps.release_contains_tag.outputs.retval }}" >> $GITHUB_OUTPUT
      - name: Pick Production or Test Environment, if tag on master or release branch respectively
        id: set_environment_name
        run: |
          DEPLOY=true
          if [[ "${{ steps.main_contains_tag.outputs.retval }}" == "true" ]]; then
            echo "ENVIRONMENT_NAME=PROD_DEPLOYMENT" >> $GITHUB_OUTPUT
          elif [[ "${{ steps.release_contains_tag.outputs.retval }}" == "true" ]]; then
            echo "ENVIRONMENT_NAME=TEST_DEPLOYMENT" >> $GITHUB_OUTPUT
          else
            echo "A tag was pushed but not on master or release branch. No deployment will be done."
            DEPLOY=false
          fi
          echo "AUTOMATED_DEPLOY=$DEPLOY" >> $GITHUB_OUTPUT

  ## JOB: PYPI UPLOAD ##
  pypi_publish:
    needs: [test_suite, check_which_git_branch_we_are_on]
    runs-on: ubuntu-latest
    # if we are on tag starting with "v" and if we are on master or dev branch
    if: startsWith(github.event.ref, 'refs/tags/v') && ${{ needs.check_which_git_branch_we_are_on.outputs.AUTOMATED_DEPLOY == 'true' }}
    environment:
      name: ${{ needs.check_which_git_branch_we_are_on.outputs.ENVIRONMENT_NAME }}
    env:
      DIST_DIR: dist
      PACKAGE_DIST_VERSION: ${{ needs.test_suite.outputs.SEMVER_PIP_FORMAT }}
      TWINE_USERNAME: ${{ secrets.TWINE_USERNAME }}
      TWINE_PASSWORD: ${{ secrets.TWINE_PASSWORD }}
      PYPI_SERVER: ${{ vars.PYPI_SERVER }}
    steps:
    - uses: actions/checkout@v3
    - name: Download Source & Wheel distributions
      uses: actions/download-artifact@v3
      with:
        path: downloaded-artifacts
    - name: Get Publishable files from the Artifacts
      run: |
        TAG="${GITHUB_REF_NAME}"
        SEM_VER="${TAG:1}"  # remove the first character (v)
        PARSER="src/cookiecutter_python/{{ cookiecutter.project_slug }}/scripts/parse_version.py"
        PARSED_VERSION=$(python "${PARSER}")
        if [[ "${PARSED_VERSION}" != "${SEM_VER}" ]]; then
          echo "ERROR: Version in __init__.py (${PARSED_VERSION}) does not match tag (${SEM_VER})"
          exit 1
        fi
    - run: mkdir ${DIST_DIR}
    - run: |
        # Get Source Distribution (tar.gz of source code)
        source_distributions=$(find downloaded-artifacts -type f -name cookiecutter_python*.tar.gz)
        source_distributions_array=($source_distributions)
        source_distribution=${source_distributions_array[0]}  # a *.tar.gz file path
        # Extract the base name (without the path)
        source_distribution_name=$(basename "$source_distribution")
        # Check if all source distribution (.tar.gz) files have the same name
        for file in "${source_distributions_array[@]}"; do
          if [ "$source_distribution_name" != "$(basename "$file")" ]; then
            echo "Error: Not all Source Distribution .tar.gz files have the same name!"
            exit 1
          fi
        done
        echo "source_distribution=$source_distribution" >> $GITHUB_ENV
    - run: cp "$source_distribution" ${DIST_DIR}
    - run: |
        # Get all built Wheels and copy to dist folder
        for f in `find downloaded-artifacts -type f -name cookiecutter_python*.whl`; do
          echo "F: $f";
          # TODO check for duplicates, which means that our build matrix produces the same wheel (need a different compiler that python such as pypy, cython, etc)
          cp $f ${DIST_DIR}
        done
    - name: Install Dependencies
      run: pip install tox==3.28
    - run: echo "Publishing $PACKAGE_DIST_VERSION to $PYPI_SERVER PyPI"
    - name: Publish to PyPI
      run: tox -vv -s false -e deploy -- upload --non-interactive --skip-existing
    - run: echo "Published :\)"


  ### STATIC CODE ANALYSIS & LINTING ###
  # Check that Code passes 'Our Quality Standards'
  lint:
    name: "Static Code Analysis"
    runs-on: ubuntu-latest
    needs: set_github_outputs
    if: ${{ needs.set_github_outputs.outputs.RUN_LINT == 'true' }}
    steps:
      - uses: actions/checkout@v3
      - name: Set up Python ${{ env.STATIC_ANALYSIS_PY }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.STATIC_ANALYSIS_PY }}
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install tox==3.28

      ## Isort ##
      - name: "Isort\\: Require Semantic and Alphabetic order of the Python Imports"
        if: ${{ matrix.platform != 'windows-latest' }}
        run: tox -e isort -vv -s false

      ## Black ##
      - name: "Black\\: Require Project Style to be followed by the Python Code"
        if: ${{ matrix.platform != 'windows-latest' }}
        run: tox -e black -vv -s false

      ## Pylint ##
      - name: Run Pylint tool on Python Code Base
        run: TOXPYTHON="python${STATIC_ANALYSIS_PY}" tox -e pylint -vv -s false | tee pylint-result.txt
      # TODO: Retire Pylint and MIGRATE to RUFF
      - run: cat pylint-result.txt

      - name: "Check Pylint Score > ${{ env.PYLINT_SCORE_THRESHOLD }}/10"
        if: ${{ matrix.platform != 'windows-latest' }}
        run: |
          SCORE=`sed -n 's/^Your code has been rated at \([-0-9.]*\)\/.*/\1/p' pylint-result.txt`
          echo "SCORE -> $SCORE"
          # threshold check
          if awk "BEGIN {exit !($SCORE >= $PYLINT_SCORE_THRESHOLD)}"; then
            echo "PyLint Passed! | Score: ${SCORE} out of 10 | Threshold: ${PYLINT_SCORE_THRESHOLD}"
          else
            echo "PyLint Failed! | Score: ${SCORE} out of 10 | Threshold: ${PYLINT_SCORE_THRESHOLD}"
            exit 1
          fi

      ## Pyflakes, Pyroma, McCabe, DodgyRun, Profile Validator ##
      - name: Run tox -e prospector
        if: ${{ matrix.platform != 'windows-latest' }}
        run: tox -e prospector -vv -s false

# DRAW PYTHON DEPENDENCY GRAPHS
  check_trigger_draw_dependency_graphs:
    runs-on: ubuntu-latest
    name: Draw Python Dependency Graphs ?
    needs: set_github_outputs
    if: needs.set_github_outputs.outputs.DRAW_DEPS_SVG_GRAPHS == 'true'
    outputs:
      SHOULD_DRAW_GRAPHS: ${{ steps.decide_if_should_draw_graphs.outputs.SHOULD_DRAW_GRAPHS }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          fetch-depth: 2
      - name: Decide if should draw graphs
        id: decide_if_should_draw_graphs
        run: |
          # if branch is master or dev; or if we are on tag starting with "v"
          if [[ ${GITHUB_REF_NAME} == "master" || ${GITHUB_REF_NAME} == "dev" || "${GITHUB_REF}" =~ refs/tags/v.* ]]; then
            SHOULD_DRAW_GRAPHS=true
          else
            echo "=============== list modified files ==============="
            git diff --name-only HEAD^ HEAD
            echo "========== check paths of modified files =========="
            git diff --name-only HEAD^ HEAD > files.txt
            SHOULD_DRAW_GRAPHS=false
            while read file; do
              echo $file
              if [[ $file =~ ^src/ ]]; then
                echo "This modified file is under the 'src' folder."
                SHOULD_DRAW_GRAPHS=true
                break
              fi
            done < files.txt
          fi
          echo "SHOULD_DRAW_GRAPHS=$SHOULD_DRAW_GRAPHS" >> $GITHUB_OUTPUT

  draw-dependencies:
    runs-on: ubuntu-latest
    needs: check_trigger_draw_dependency_graphs
    if: needs.check_trigger_draw_dependency_graphs.outputs.SHOULD_DRAW_GRAPHS == 'true'
    name: Draw Python Dependencies as Graphs, in .svg
    steps:
    - uses: actions/checkout@v3
    - name: Set up Python 3.10
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    - name: Install tox
      run: |
        python -m pip install --upgrade pip
        python -m pip install tox==3.28
    - name: Install dependencies (ie dot binary of graphviz)
      run: |
        sudo apt-get update -y --allow-releaseinfo-change
        sudo apt-get install -y graphviz
    - name: Draw Dependency Graphs as .svg files
      run: tox -e pydeps -vv -s false
    - name: Upload Dependency Graphs as artifacts
      uses: actions/upload-artifact@v3
      with:
        name: dependency-graphs
        path: pydeps/
        if-no-files-found: warn  # 'error' or 'ignore' are also available, defaults to `warn`
