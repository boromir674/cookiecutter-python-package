[tox]
envlist =
    {py311, py310, py39, py38, py37}-{dev, sdist, wheel}-{linux, macos, windows}
    coverage
isolated_build = true
skip_missing_interpreters = true


[gh-actions]
python =
    3.7: {py37}{, -path, -sdist, -wheel, -dev}
    3.8: {py38}{, -path, -sdist, -wheel, -dev}
    3.9: {py39}{, -path, -sdist, -wheel, -dev}
    3.10: {py310}{, -path, -sdist, -wheel, -dev}
    3.11: {py311}{, -path, -sdist, -wheel, -dev}


[gh-actions:env]
PLATFORM =
    ubuntu-latest: linux
    macos-latest: macos
    windows-latest: windows


[testenv]
description = An environment designed to facilitate testing (running the test suite)
passenv =
    *
    LC_ALL
    PIP_*
    PYTEST_*
    # See https://github.com/codecov/codecov-python/blob/5b9d539a6a09bc84501b381b563956295478651a/README.md#using-tox
    codecov: TOXENV
    codecov: CI
    codecov: TRAVIS TRAVIS_*
setenv =
# It will overide variables in passenv in case of collision
    PYTHONPATH = {toxinidir}{/}tests
    PYTHONBUFFERED = yes
    TEST_RESULTS_DIR = {toxinidir}{/}test-results
    MYPYPATH = {toxinidir}{/}src{/}stubs
    PY_PACKAGE = cookiecutter_python
    DIST_DIR = dist
    COVERAGE_FILE = {toxworkdir}{/}.coverage.{envname}
    TEST_STATUS_DIR = {envtmpdir}
    PYPY3323BUG = 1
    black,lint,isort,ruff: LINT_ARGS = "tests src{/}cookiecutter_python{/}backend src{/}cookiecutter_python{/}handle"

    # For Windows: account for inability to do post Gen delete of log file in
    # Gen Proj Dir, due to Permission Error, when running on windows:
    # other process is using the file, so removing is denied, at Generator runtime

    # log deletion post hook fails on windows, due to permission error! (other process is using the file, so removing is denied)
    # windows spawn multiple processes, so log deletion is not possible, even when running 1 Single Uni Tests
    BUG_LOG_DEL_WIN = permission_error

extras =
    test
commands =
# --cov-config pyproject.toml
    pytest -ra --cov --cov-report=term-missing \
      --cov-report=html:{envdir}/htmlcov --cov-context=test \
      --cov-report=xml:{toxworkdir}/coverage.{envname}.xml \
      {posargs:-n auto {toxinidir}{/}tests}


## DEV on CI ##
[testenv:{py311, py310, py39, py38, py37, py36, pypy3}-dev{, -linux, -macos, -windows}]
description = Install in 'edit' mode & Test
usedevelop = true

# Designed for local developement
[testenv:dev]
description = Using `python3` in PATH: Install in 'edit' mode & Test
basepython = {env:TOXPYTHON:python3}
deps = tox  # required when enabling --run-integration pytest flag
usedevelop = true
commands = pytest -ra {posargs:-n auto} {toxinidir}{/}tests

[testenv:dev-cov]
description = Using `python3` in PATH: Install in 'edit' mode, Test & measure Coverage
basepython = {env:TOXPYTHON:python3}
deps = tox  # required when enabling --run-integration pytest flag
usedevelop = true
commands =
    pytest -ra --cov --cov-report=term-missing \
      --cov-report=html:{envdir}/htmlcov --cov-context=test \
      --cov-report=xml:{toxworkdir}/coverage.{envname}.xml \
      {posargs:-n auto} {toxinidir}{/}tests

[testenv:coverage]
description = combine coverage from test environments
passenv =
    DIFF_AGAINST
    TOX_COVERAGE_FILE
setenv =
    COVERAGE_FILE = {env:TOX_COVERAGE_FILE:{toxworkdir}/.coverage}
skip_install = true
deps =
    coverage[toml]>=5.1
    diff_cover>=6
parallel_show_output = true
commands_pre = python -c 'import os; print("-----\n" + os.environ.get("COVERAGE_FILE"))'
commands =
    coverage combine --keep
    coverage report --skip-covered --show-missing -i
    coverage xml -o {toxworkdir}/coverage.xml -i
    coverage html -d {toxworkdir}/htmlcov -i
depends = {py311, py310, py39, py38, py37, py36}{, -path, -sdist, -wheel, -dev}

# PATH
[testenv:{py311, py310, py39, py38, py37, py36, pypy3}-path{, -linux, -macos, -windows}]
description = Add Source Code to Path & Test
setenv =
    {[testenv]setenv}
    PYTHONPATH = {toxinidir}{/}src{:}{toxinidir}{/}tests
deps = poetry
skip_install = true
commands =
    poetry install --no-root -E test
    {[testenv]commands}

# SDIST
[testenv:{py311-, py310-, py39-, py38-, py37-, py36-, pypy3-,}sdist{, -linux, -macos, -windows}]
description = Install as Source Distribution & Test
basepython = {env:TOXPYTHON:python3}

# WHEEL
[testenv:{py311-, py310-, py39-, py38-, py37-, py36-, pypy3-,}wheel{, -linux, -macos, -windows}]
description = Install as Wheel & Test
basepython = {env:TOXPYTHON:python3}
skip_install = true
changedir = {toxinidir}
commands_pre =
    python -c 'import os; d = "{env:DIST_DIR}"; import shutil; exec("if os.path.exists(d):\n    shutil.rmtree(d)");'
commands =
    pip wheel --wheel-dir {toxworkdir}{/}{env:DIST_DIR} {toxinidir}
    pip install --exists-action w --force-reinstall "{toxworkdir}{/}{env:DIST_DIR}{/}{env:PY_PACKAGE}-{env:PKG_VERSION}-py3-none-any.whl[test]"
    {[testenv]commands}



[testenv:dev-env]
description = generate a DEV environment
usedevelop = true
extras =
    {[testenv]extras}
    docs
    typing
commands =
    python -m pip list --format=columns
    python -c 'import sys; print(sys.executable)'
    python -m pip freeze > {envdir}{/}requirements-dev.txt


## STATIC TYPE CHECKING
[testenv:type]
description = Type checking with mypy
basepython = {env:TOXPYTHON:python3}
extras = typing
usedevelop = true
changedir = {toxinidir}
commands_pre =
    # trick mypy into believing that tests is a package, beucase it wants to be able to distinguish our 2 conftest.py files
    # create empty __init__.py in tests, temporarily
    python -c 'open("tests/__init__.py", "a").close();'
commands =
    mypy --show-error-codes \
    --exclude tests/data \
    {posargs:src{/}{env:PY_PACKAGE}{/}hooks \
    src{/}{env:PY_PACKAGE}{/}backend tests src{/}{env:PY_PACKAGE}{/}handle \
    src{/}{env:PY_PACKAGE}{/}utils.py src{/}{env:PY_PACKAGE}{/}exceptions.py \
    src{/}{env:PY_PACKAGE}{/}cli.py src{/}{env:PY_PACKAGE}{/}cli_handlers.py \
    src{/}{env:PY_PACKAGE}{/}__main__.py src{/}{env:PY_PACKAGE}{/}__init__.py}
commands_post =
    # delete temporarily created empty __init__.py in tests
    python -c 'import os; os.remove("tests/__init__.py");'


## DOCUMENTATION
[testenv:docs]
description = Build the documentation. Read the source .rst and .py files and
    build ready-to-render/ready-to-serve html (eg you can host it in a
    'read the docs server'). Before building, any sphinx doctest found is
    executed. After building, both word spelling and url links proper redirects
    are checked.
setenv =
    {[testenv]setenv}
    SPELLCHECK=1
extras = docs
usedevelop = true
changedir = {toxinidir}
commands =
    sphinx-build {posargs:-E} -b doctest docs {env:DOCS_BUILD_LOCATION:dist{/}docs}
    sphinx-build {posargs:-E} -b html docs {env:DOCS_BUILD_LOCATION:dist{/}docs}
    sphinx-build -b spelling docs {env:DOCS_BUILD_LOCATION:dist{/}docs}
    - sphinx-build -b linkcheck docs {env:DOCS_BUILD_LOCATION:dist{/}docs}
    python -c 'print("View documentation at {env:DOCS_BUILD_LOCATION:dist/docs}/index.html; it is ready to be hosted!")'

[testenv:live-html]
description = Rebuild Sphinx documentation on changes, with live-reload in the browser.
setenv =
    {[testenv]setenv}
    SPELLCHECK=1
deps = sphinx-autobuild
extras = docs
usedevelop = true
commands = sphinx-autobuild docs docs{/}_build{/}html {posargs}


## PYTHON PACKAGING
[testenv:build]
description = Create a source and wheel distribution.
    Creates .tar.gz and .whl files in the {env:DIST_DIR} folder, that can be upload to a pypi index server.
basepython = {env:TOXPYTHON:python3}
deps = build
skip_install = true
changedir = {toxinidir}
commands_pre =
    python -c 'import os; import shutil; d = "{env:DIST_DIR}"; exec("if os.path.exists(d):\n    shutil.rmtree(d)");'
commands = python -m build {toxinidir} --outdir {env:DIST_DIR}

[testenv:check]
description = Check the code for compliance with best practises of Python packaging ecosystem (PyPI, pip, Distribute, etc).
deps =
    poetry-core
    pyroma
    twine
skip_install = true
commands =
    pyroma --directory {toxinidir}
    pyroma --file {env:DIST_DIR}/{env:PY_PACKAGE}-{env:PKG_VERSION}.tar.gz
    python -m twine check {env:DIST_DIR}/{env:PY_PACKAGE}-{env:PKG_VERSION}*
    # TODO Improvement run 'pyroma --pypi' from some script/CI server after uploading to test-pypi
depends = build


## DEPLOYMENT
[testenv:deploy]
# Deploy to test.pypi.org : TWINE_USERNAME=user TWINE_PASSWROD=pass PACKAGE_DIST_VERSION=1.0.0 tox -e deploy
# Deploy to pypi.org      : TWINE_USERNAME=user TWINE_PASSWROD=pass PACKAGE_DIST_VERSION=1.0.0 PYPI_SERVER=pypi tox -e deploy
description = Deploy the python package to be hosted in a pypi server. Requires to authenticate with the pypi
    server, so please set the TWINE_PASSWORD and TWINE_PASSWORD environment variables.
    Also, requires the PACKAGE_DIST_VERSION variable to explicitly indicate which distribution
    (semantic version: ie 0.5.3, 1.0.0) we intent to deploy/upload. That way we avoid unintentionally deploying
    a wrong version and we make sure that the correct version is released to pypi. By default, deploys to a
    pypi 'test server', currently at test.pypi.org. If you want to deploy to the "production" pypi (at pypi.org),
    then you have to set the PYPI_SERVER environment variable to 'pypi', like `export PYPI_SERVER=pypi`.
    Before deploying, certain sanity checks are ran on the distribution artefacts (ie .tar.gz, .whl) to be uploaded.
passenv =
    PACKAGE_DIST_VERSION
    TWINE_USERNAME
    TWINE_PASSWORD
deps =
    keyring==21.3.0
    twine==3.4.0
skip_install = true
commands_pre =
    python -c 'import os; n = "TWINE_USERNAME"; v = os.environ.get(n); exec("if not v:\n    print(\"Please set the \" + str(n) + \" variable.\")\n    exit(1)");'
    python -c 'import os; n = "TWINE_PASSWORD"; v = os.environ.get(n); exec("if not v:\n    print(\"Please set the \" + str(n) + \" variable.\")\n    exit(1)");'
    python -c 'import os; n = "PACKAGE_DIST_VERSION"; v = os.environ.get(n); exec("if not v:\n    print(\"Please set the \" + str(n) + \" variable.\")\n    exit(1)");'
    python -c 'import os; n = "PYPI_SERVER"; exec("if n in os.environ:\n    v = os.environ[n]\n    if v != \"pypi\":\n        print(\"Environment variable PYPI_SERVER detected, but was not set to pypi. Please set to pypi or run tox -e deploy from an environment where the PYPI_SERVER variable is NOT present at all.\")\n        exit(1)");'
    python -m twine check {env:DIST_DIR}/{env:PY_PACKAGE}-{env:PACKAGE_DIST_VERSION:MISSMATCHED_PACKAGE_DIST_VERSION_ERROR}*
commands =
    twine {posargs:upload --non-interactive} --repository {env:PYPI_SERVER:testpypi --skip-existing} {env:DIST_DIR}{/}{env:PY_PACKAGE}-{env:PACKAGE_DIST_VERSION:MISSMATCHED_PACKAGE_DIST_VERSION_ERROR}* --verbose


## COVERAGE
[testenv:clean]
description = Clean the working directory from any previously computed code coverage results.
    Removes any data resulted from measuring code coverage. Useful before running the test suite
    with code coverage enabled.
deps = coverage
skip_install = true
commands = coverage erase

[testenv:report]
description = Show the most recently computed code coverage results.
deps = coverage
skip_install = true
commands = {posargs:coverage report}


# CODE LINTING, STATIC (STYLE) CHECKING
[sca]
setenv =
    {[testenv]setenv}
    TESTS_DIR_NAME = 'tests'
    TEST_DATA_DIR_NAME = 'data'
    TEST_SNAPSHOTS_DIR_NAME = 'snapshots'

    # Exclude Test Snapshots from Isort and Black, since they contain Python Code
    ISORT_EXCLUDE = '{env:TESTS_DIR_NAME}{/}{env:TEST_DATA_DIR_NAME}{/}{env:TEST_SNAPSHOTS_DIR_NAME}'
    BLACK_EXCLUDE = '{env:TESTS_DIR_NAME}/{env:TEST_DATA_DIR_NAME}/{env:TEST_SNAPSHOTS_DIR_NAME}'
    # Note: we use forward slashes (/), because Black resolves paths under the hood

[testenv:lint]
description = test if code conforms with our styles
    to check against code style (aka lint check) run: tox -e lint
    to apply code style (aka lint apply) run: APPLY_LINT= tox -e lint
deps =
    black
    isort >= 5.0.0
passenv = APPLY_LINT
skip_install = true
changedir = {toxinidir}
commands =
    isort {posargs:{env:APPLY_LINT:--check}} "{env:LINT_ARGS:.}"
    black {posargs:{env:APPLY_LINT:--check}} -S --config pyproject.toml "{env:LINT_ARGS:.}"

# black --check --skip-string-normalization --exclude tests/data/snapshots --config pyproject.toml tests src/cookiecutter_python/backend src/cookiecutter_python/handle
[testenv:black]
# To see DIFF: `tox -e black -- --diff`
# To APPLY! : `APPLY_BLACK= tox -e black`
description = black ops
deps = black
setenv = {[sca]setenv}
skip_install = true
changedir = {toxinidir}
commands = black {posargs:{env:APPLY_BLACK:--check}} \
    --skip-string-normalization \
    --exclude {env:BLACK_EXCLUDE} \
    --config pyproject.toml "{env:LINT_ARGS:.}"

# isort --skip tests/data/snapshots --check tests src/cookiecutter_python/backend src/cookiecutter_python/handle
[testenv:isort]
# To see DIFF: tox -e isort -- --diff
# To APPLY! : `APPLY_ISORT= tox -e isort`
description = isort
deps = isort >= 5.0.0
setenv = {[sca]setenv}
skip_install = true
changedir = {toxinidir}
commands = isort \
    --skip {env:ISORT_EXCLUDE} \
    {posargs:{env:APPLY_ISORT:--check}} \
    "{env:LINT_ARGS:.}"

## RUFF ##
# To see DIFF    : tox -e ruff -- --diff
# To APPLY!      : `tox -e ruff -- --fix`
# To APPLY More! : `tox -e ruff -- --fix --unsafe-fixes`
[testenv:ruff]
description = Run the ruff static analysis tool
basepython = {env:TOXPYTHON:python3}
deps = ruff
skip_install = true
# make sure to avoid checking the Template pyproject.toml, due to parse error
commands = ruff check "{env:LINT_ARGS:.}" {posargs}


[testenv:bandit]
description = static code security check, configured in pyproject.toml
deps = bandit[toml]
skip_install = true
commands = bandit -r -c pyproject.toml {posargs:src tests}

[testenv:pylint]
description = Run the Pylint tool to analyse the Python code and output
    information about errors, potential problems and convention violations
deps =
    pylint ; python_version == '3.11'
    pylint == 2.7.4 ; python_version < '3.11'
usedevelop = true
changedir = {toxinidir}
commands =
    - python -m pylint src{/}{env:PY_PACKAGE}
    - python -m pylint tests

[testenv:prospector]
description = Run multiple static code analysis tools defined in .prospector.yml
    Runs the prospector tool which brings together the functionality of other
    Python analysis tools such as Pyflakes and McCabe complexity.
    We run tools: Pyflakes, Pyroma, McCabe and Dodgy
deps = prospector[with_pyroma] == 1.3.1
skip_install = true
changedir = {toxinidir}
commands_pre =
    # We do not run pylint, since we have a dedicated pylint env for it.
    # Prospector still tries to read .pylintrc, which causes a crash (because .pylintrc was generated with a pylint version higher than the one supported by prospector)
    # So we temporarily "hide" .pylintrc from prospector
    python -c 'import os; f = ".pylintrc"; exec("if os.path.exists(f):\n    os.rename(f, \".pylintrc-bak\")")'
commands =
    prospector src
    prospector tests
commands_post =
    # We "restore" .pylintrc (to be available to the pylint env command)
    python -c 'import os; f = ".pylintrc-bak"; exec("if os.path.exists(f):\n    os.rename(f, \".pylintrc\")")'


## GENERATE ARCHITECTURE GRAPHS
[testenv:pydeps]
description =
    Visualise Python dependency graphs (roughly which module imports which) and store in .svg file(s).
    Eg: `tox -e pydeps`, `PYDEPS_DIR=my-destination-dir tox -e pydeps`.
    PYDEPS_DIR controls the relative location (to your current working dir) of the target dir to store
    the generated files. The default target dir is 'pydeps'. Dir is created if it doesn't exist.
    Requires the 'dot' executable to be in your PATH. Installing the graphviz library should make
    the dot executable available in your PATH. Installing 'graphviz':
    * For Linux, please run "sudo apt install graphviz"
    * For MacOS, please run "brew install graphviz"
basepython = {env:TOXPYTHON:python3.10}
passenv =
    HOME
    PWD
    PYDEPS_DIR
deps = pydeps==1.11.0
usedevelop = true
commands_pre =
    python -c 'from pathlib import Path; import os; p = Path(os.environ["PWD"]) / os.getenv("PYDEPS_DIR", "pydeps"); p.mkdir(parents=True, exist_ok=True);'
commands =
    pydeps --version

    # --max-bacon : exclude nodes that are more than n hops away
    # (default=2, 0 -> infinite)

    # --min-cluster-size : the minimum number of nodes a dependency must have before being clustered (default=0)

    # --max-cluster-size : the maximum number of nodes a dependency can have before the cluster is collapsed to a single node (default=0)
    # --keep-target-cluster : draw target module as a cluster

    # Draw only the source code package inner dependencies
    pydeps src{/}{env:PY_PACKAGE} --only {env:PY_PACKAGE} --noshow -o {env:PWD}{/}{env:PYDEPS_DIR:pydeps}{/}deps_inner.svg
    ; # Draw the source code package inner and external dependencies
    pydeps src{/}{env:PY_PACKAGE} --cluster --noshow -o {env:PWD}{/}{env:PYDEPS_DIR:pydeps}{/}deps_all.svg

    ; # Visualize the package inner dependencies and abstract the external (eg with numpy, pandas, etc) ones
    ; # Draw the source code package inner and minimum external dependencies
    pydeps src{/}{env:PY_PACKAGE} --max-cluster-size=2 --keep-target-cluster --noshow -o {env:PWD}{/}{env:PYDEPS_DIR:pydeps}{/}deps_ktc-mcs_2.svg

    ; # Draw the source code package inner and all external dependencies
    pydeps src{/}{env:PY_PACKAGE} --keep-target-cluster --noshow -o {env:PWD}{/}{env:PYDEPS_DIR:pydeps}{/}deps_ktc.svg

    python -c 'from pathlib import Path; p = Path("{env:PWD}{/}{env:PYDEPS_DIR:pydeps}"); print(f"\nGenerated .svg files in \"\{str(p.absolute())\}\".");'
