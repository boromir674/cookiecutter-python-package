[tox]
envlist =
    {py311, py310, py39, py38, py37, py36}-{dev, sdist, wheel}-{linux, macos, windows}
    coverage
isolated_build = true
skip_missing_interpreters = true
minversion = 3.14
requires = virtualenv >= 20.0.34


[gh-actions]
python =
    3.6: {py36}{, -path, -sdist, -wheel, -dev}
    3.7: {py37}{, -path, -sdist, -wheel, -dev}
    3.8: {py38}{, -path, -sdist, -wheel, -dev}
    3.9: {py39}{, -path, -sdist, -wheel, -dev}
    3.10: {py310}{, -path, -sdist, -wheel, -dev}
    3.11: {py311}{, -path, -sdist, -wheel, -dev}


[gh-actions:env]
PLATFORM =
    ubuntu-latest: linux
    macos-latest: macos
    windows-latest: windows


[testenv]
description = An environment designed to facilitate testing (running the test suite)
passenv =
    *
    LC_ALL
    PIP_*
    PYTEST_*
    # See https://github.com/codecov/codecov-python/blob/5b9d539a6a09bc84501b381b563956295478651a/README.md#using-tox
    codecov: TOXENV
    codecov: CI
    codecov: TRAVIS TRAVIS_*
setenv =
# It will overide variables in passenv in case of collision
    PYTHONPATH = {toxinidir}{/}tests
    PYTHONBUFFERED = yes
    TEST_RESULTS_DIR = {toxinidir}{/}test-results
    MYPYPATH = {toxinidir}{/}src{/}stubs
    PY_PACKAGE = {{ cookiecutter.pkg_name }}
    DIST_DIR = dist
    COVERAGE_FILE = {toxworkdir}{/}.coverage.{envname}
    TEST_STATUS_DIR = {envtmpdir}
    PYPY3323BUG = 1
    black,lint,isort,ruff: LINT_ARGS = "src tests scripts"
extras =
    test
commands =
# --cov-config pyproject.toml
    pytest -ra --cov --cov-report=term-missing \
      --cov-report=html:{envdir}/htmlcov --cov-context=test \
      --cov-report=xml:{toxworkdir}/coverage.{envname}.xml \
      {posargs:-n auto} tests


# PATH
[testenv:{py311, py310, py39, py38, py37, py36, pypy3}-path{, -linux, -macos, -windows}]
description = Add Source Code to Path & Test
setenv =
    {[testenv]setenv}
    PYTHONPATH = {toxinidir}{/}src{:}{toxinidir}{/}tests
deps = poetry
skip_install = true
commands =
    poetry install --no-root -E test
    {[testenv]commands}

# SDIST
[testenv:{py311, py310, py39, py38, py37, py36, pypy3}-sdist{, -linux, -macos, -windows}]
description = Install as Source Distribution & Test

# WHEEL
[testenv:{py311, py310, py39, py38, py37, py36, pypy3}-wheel{, -linux, -macos, -windows}]
description = Install as Wheel & Test
skip_install = true
changedir = {toxinidir}
commands_pre =
    python -c 'import os; d = "{env:DIST_DIR}"; import shutil; exec("if os.path.exists(d):\n    shutil.rmtree(d)");'
commands =
    pip wheel --wheel-dir {toxworkdir}{/}{env:DIST_DIR} --cache-dir {envdir} {toxinidir}
    pip install --exists-action w --force-reinstall "{toxworkdir}{/}{env:DIST_DIR}{/}{env:PY_PACKAGE}-{env:PKG_VERSION}-py3-none-any.whl[test]"
    {[testenv]commands}

# DEV
[testenv:{py311, py310, py39, py38, py37, py36, pypy3}-dev{, -linux, -macos, -windows}]
description = Install in 'edit' mode & Test
usedevelop = true


# INTEGRATION TEST
[testenv:{py311, py310, py39, py38, py37, py36, pypy3}-integration{, -linux, -macos, -windows}]
description = Integration Testing in 'edit' mode
deps = tox
usedevelop = true
commands =
    pytest -ra --cov --cov-report=term-missing \
      --cov-report=html:{envdir}/htmlcov --cov-context=test \
      --cov-report=xml:{toxworkdir}/coverage.{envname}.xml \
      {posargs:-n auto} tests --run-integration --run-network_bound

# Designed for local developement
[testenv:dev]
description = Using `python3` in PATH: Install in 'edit' mode & Test
basepython = {env:TOXPYTHON:python3}
deps = tox  # required when enabling --run-integration pytest flag
usedevelop = true
commands = pytest -ra {posargs:-n auto} {toxinidir}{/}tests

[testenv:dev-cov]
description = Using `python3` in PATH: Install in 'edit' mode, Test & measure Coverage
basepython = {env:TOXPYTHON:python3}
deps = tox  # required when enabling --run-integration pytest flag
usedevelop = true
commands =
    pytest -ra --cov --cov-report=term-missing \
      --cov-report=html:{envdir}/htmlcov --cov-context=test \
      --cov-report=xml:{toxworkdir}/coverage.{envname}.xml \
      {posargs:-n auto} {toxinidir}{/}tests


[testenv:coverage]
description = combine coverage from test environments
passenv =
    DIFF_AGAINST
setenv =
    COVERAGE_FILE = {toxworkdir}/.coverage
skip_install = true
deps =
    coverage[toml]>=5.1
    diff_cover>=6
parallel_show_output = true
commands =
    coverage combine
    coverage report --skip-covered --show-missing -i
    coverage xml -o {toxworkdir}/coverage.xml -i
    coverage html -d {toxworkdir}/htmlcov -i
depends = {py311, py310, py39, py38, py37, py36}{, -path, -sdist, -wheel, -dev}


[testenv:dev-env]
description = generate a DEV environment
usedevelop = true
extras =
    {[testenv]extras}
    docs
    typing
commands =
    python -m pip list --format=columns
    python -c 'import sys; print(sys.executable)'
    python -m pip freeze > {envdir}{/}requirements-dev.txt


## STATIC TYPE CHECKING

[testenv:type]
description = Type checking with mypy
basepython = {env:TOXPYTHON:python3}
extras = typing
usedevelop = true
changedir = {toxinidir}
commands = mypy --show-error-codes {posargs:src{/}{env:PY_PACKAGE} tests}


## DOCUMENTATION

[testenv:docs]
description = Build the documentation. Read the source .rst and .py files and
    build ready-to-render/ready-to-serve html (eg you can host it in a
    'read the docs server'). Before building, any sphinx doctest found is
    executed. After building, both word spelling and url links proper redirects
    are checked.
setenv =
    {[testenv]setenv}
    SPELLCHECK=1
extras = docs
usedevelop = true
commands =
    sphinx-build {posargs:-E} -b doctest docs {env:DOCS_BUILD_LOCATION:dist{/}docs}
    sphinx-build {posargs:-E} -b html docs {env:DOCS_BUILD_LOCATION:dist{/}docs}
    sphinx-build -b spelling docs {env:DOCS_BUILD_LOCATION:dist{/}docs}
    - sphinx-build -b linkcheck docs {env:DOCS_BUILD_LOCATION:dist{/}docs}
    python -c 'print("View documentation at {env:DOCS_BUILD_LOCATION:dist/docs}/index.html; it is ready to be hosted!")'


[testenv:live-html]
description = Rebuild Sphinx documentation on changes, with live-reload in the browser.
setenv =
    {[testenv]setenv}
    SPELLCHECK=1
deps = sphinx-autobuild
extras = docs
usedevelop = true
commands =
    sphinx-autobuild docs docs{/}_build{/}html {posargs}


## PYTHON PACKAGING

[testenv:build]
description = Create a source and wheel distribution.
    Creates .tar.gz and .whl files in the {env:DIST_DIR} folder, that can be upload to a pypi index server.
basepython = {env:TOXPYTHON:python3}
deps = build
skip_install = true
changedir = {toxinidir}
commands_pre =
    python -c 'import os; import shutil; d = "{env:DIST_DIR}"; exec("if os.path.exists(d):\n    shutil.rmtree(d)");'
commands =
    python -m build {toxinidir} --outdir {env:DIST_DIR}

[testenv:check]
description = Check the code for compliance with best practises of Python packaging ecosystem (PyPI, pip, Distribute, etc).
deps =
    poetry-core
    pyroma
    twine
skip_install = true
commands =
    pyroma --directory {toxinidir}
    pyroma --file {env:DIST_DIR}/{env:PY_PACKAGE}-{env:PKG_VERSION}.tar.gz
    python -m twine check {env:DIST_DIR}/{env:PY_PACKAGE}-{env:PKG_VERSION}*
    # TODO Improvement run 'pyroma --pypi' from some script/CI server after uploading to test-pypi
depends = build


## DEPLOYMENT

[testenv:deploy]
# Deploy to test.pypi.org : TWINE_USERNAME=user TWINE_PASSWROD=pass PACKAGE_DIST_VERSION=1.0.0 tox -e deploy
# Deploy to pypi.org      : TWINE_USERNAME=user TWINE_PASSWROD=pass PACKAGE_DIST_VERSION=1.0.0 PYPI_SERVER=pypi tox -e deploy
description = Deploy the python package to be hosted in a pypi server. Requires to authenticate with the pypi
    server, so please set the TWINE_PASSWORD and TWINE_PASSWORD environment variables.
    Also, requires the PACKAGE_DIST_VERSION variable to explicitly indicate which distribution
    (semantic version: ie 0.5.3, 1.0.0) we intent to deploy/upload. That way we avoid unintentionally deploying
    a wrong version and we make sure that the correct version is released to pypi. By default, deploys to a
    pypi 'test server', currently at test.pypi.org. If you want to deploy to the "production" pypi (at pypi.org),
    then you have to set the PYPI_SERVER environment variable to 'pypi', like `export PYPI_SERVER=pypi`.
    Before deploying, certain sanity checks are ran on the distribution artefacts (ie .tar.gz, .whl) to be uploaded.
passenv =
    PACKAGE_DIST_VERSION
    TWINE_USERNAME
    TWINE_PASSWORD
deps =
    keyring==21.3.0
    twine==3.4.0
skip_install = true
commands_pre =
    python -c 'import os; n = "TWINE_USERNAME"; v = os.environ.get(n); exec("if not v:\n    print(\"Please set the \" + str(n) + \" variable.\")\n    exit(1)");'
    python -c 'import os; n = "TWINE_PASSWORD"; v = os.environ.get(n); exec("if not v:\n    print(\"Please set the \" + str(n) + \" variable.\")\n    exit(1)");'
    python -c 'import os; n = "PACKAGE_DIST_VERSION"; v = os.environ.get(n); exec("if not v:\n    print(\"Please set the \" + str(n) + \" variable.\")\n    exit(1)");'
    python -c 'import os; n = "PYPI_SERVER"; exec("if n in os.environ:\n    v = os.environ[n]\n    if v != \"pypi\":\n        print(\"Environment variable PYPI_SERVER detected, but was not set to pypi. Please set to pypi or run tox -e deploy from an environment where the PYPI_SERVER variable is NOT present at all.\")\n        exit(1)");'
    python -m twine check {env:DIST_DIR}/{env:PY_PACKAGE}-{env:PACKAGE_DIST_VERSION:MISSMATCHED_PACKAGE_DIST_VERSION_ERROR}*
commands =
    python -m twine {posargs:upload --non-interactive} --repository {env:PYPI_SERVER:testpypi --skip-existing} {env:DIST_DIR}{/}{env:PY_PACKAGE}-{env:PACKAGE_DIST_VERSION:MISSMATCHED_PACKAGE_DIST_VERSION_ERROR}* --verbose


## COVERAGE

[testenv:clean]
description = Clean the working directory from any previously computed code coverage results.
    Removes any data resulted from measuring code coverage. Useful before running the test suite
    with code coverage enabled.
deps = coverage
skip_install = true
commands = coverage erase

[testenv:report]
description = Show the most recently computed code coverage results.
deps = coverage
skip_install = true
commands = {posargs:coverage report}

[testenv:format-report]
description = Generate xml and html formatted files out of previously computed code coverage results.
deps = coverage
skip_install = true
commands =
    coverage xml
    coverage html


# CODE LINTING, STATIC (STYLE) CHECKING

[testenv:lint]
description = test if code conforms with our styles
    to check against code style (aka lint check) run: tox -e lint
    to apply code style (aka lint apply) run: APPLY_LINT= tox -e lint
deps =
    black
    isort >= 5.0.0
passenv = APPLY_LINT
skip_install = true
changedir = {toxinidir}
commands =
    isort {posargs:{env:APPLY_LINT:--check}} "{env:LINT_ARGS:.}"
    black {posargs:{env:APPLY_LINT:--check}} -S --config pyproject.toml "{env:LINT_ARGS:.}"


[testenv:black]
description = black ops
deps = black
skip_install = true
changedir = {toxinidir}
commands = black {posargs:{env:APPLY_BLACK:--check}} --skip-string-normalization \
    --config pyproject.toml "{env:LINT_ARGS:.}"

[testenv:isort]
description = isort
deps = isort >= 5.0.0
skip_install = true
changedir = {toxinidir}
commands = isort {posargs:{env:APPLY_ISORT:--check}} "{env:LINT_ARGS:.}"

[testenv:bandit]
description = static code security check
deps = bandit[toml]
skip_install = true
commands = bandit -r -c pyproject.toml {posargs:src tests}

## Code Static Analysis

## RUFF ##
# To see DIFF    : tox -e ruff -- --diff
# To APPLY!      : `tox -e ruff -- --fix`
# To APPLY More! : `tox -e ruff -- --fix --unsafe-fixes`
[testenv:ruff]
description = Run the ruff static analysis tool
basepython = {env:TOXPYTHON:python3}
deps = ruff
skip_install = true
commands = ruff check "{env:LINT_ARGS:.}" {posargs}

[testenv:pylint]
description = Run the Pylint tool to analyse the Python code and output
    information about errors, potential problems and convention violations
deps =
    pylint ; python_version == '3.11'
    pylint == 2.7.4 ; python_version < '3.11'
usedevelop = true
changedir = {toxinidir}
commands =
    - python -m pylint src{/}{env:PY_PACKAGE}
    - python -m pylint tests


[testenv:prospector]
description = Analyse Python code and output information about errors, potential problems, convention violations and complexity.
    Runs the prospector tool which brings together the functionality of other Python analysis tools such as Pyflakes and McCabe complexity.
    We run tools: Pyflakes, Pyroma, McCabe and Dodgy
deps = prospector[with_pyroma] == 1.3.1
skip_install = true
changedir = {toxinidir}
commands_pre =
    # We do not run pylint, since we have a dedicated pylint env for it.
    # Prospector still tries to read .pylintrc, which causes a crash (because .pylintrc was generated with a pylint version higher than the one supported by prospector)
    # So we temporarily "hide" .pylintrc from prospector
    python -c 'import os; f = ".pylintrc"; exec("if os.path.exists(f):\n    os.rename(f, \".pylintrc-bak\")")'
commands = prospector .
commands_post =
    # We "restore" .pylintrc (to be available to the pylint env command)
    python -c 'import os; f = ".pylintrc-bak"; exec("if os.path.exists(f):\n    os.rename(f, \".pylintrc\")")'


## GENERATE ARCHITECTURE GRAPHS

[testenv:graphs]
description = Visualise the dependency graphs (roughly which module imports which), by examining the
    Python code. The dependency graph(s) are rendered in .svg file(s) and saved on the disk. By default, the generated
    files are stored in the 'pydoer-graphs' directory, inside the project's root folder. You can use the PYDOER_GRAPHS
    environment variable to determine the directory location to store the files. If the directory does not exist
    it gets created. Requires that the 'dot' executable is in your PATH. Installing the graphviz library should make
    the dot executable available in your PATH. Installing 'graphviz':
    * For Linux users using Debian-based distributions (ie Ubuntu, Debian, Mint), please run "sudo apt install graphviz"
    * For MacOS users with Homebrew, please run "brew install graphviz"
basepython = {env:TOXPYTHON:python3.8}
passenv =
    HOME
    PYDOER_GRAPHS
deps =
    pydeps==1.9.13
usedevelop = true
changedir = {toxinidir}
commands_pre =
    python -c 'import os; p = "{env:PYDOER_GRAPHS:pydoer-graphs}"; exec("if not os.path.exists(p):\n    os.mkdir(p)");'
commands =
    pydeps --version

    # --max-bacon : exclude nodes that are more than n hops away
    # (default=2, 0 -> infinite)

    # --min-cluster-size : the minimum number of nodes a dependency must have before being clustered (default=0)

    # --max-cluster-size : the maximum number of nodes a dependency can have before the cluster is collapsed to a single node (default=0)
    # --keep-target-cluster : draw target module as a cluster

    # Draw only the source code package inner dependencies
    pydeps src{/}{env:PY_PACKAGE} --only {env:PY_PACKAGE} --noshow -o {env:PYDOER_GRAPHS:pydoer-graphs}{/}deps_inner.svg
    # Draw the source code package inner and external dependencies
    pydeps src{/}{env:PY_PACKAGE} --cluster --noshow -o {env:PYDOER_GRAPHS:pydoer-graphs}{/}deps_all.svg

    # Visualize the package inner dependencies and abstract the external (eg with numpy, pandas, etc) ones
    # Draw the source code package inner and minimum external dependencies
    pydeps src{/}{env:PY_PACKAGE} --max-cluster-size=2 --keep-target-cluster --noshow -o {env:PYDOER_GRAPHS:pydoer-graphs}{/}deps_ktc-mcs_2.svg

    # Draw the source code package inner and all external dependencies
    pydeps src{/}{env:PY_PACKAGE} --keep-target-cluster --noshow -o {env:PYDOER_GRAPHS:pydoer-graphs}{/}deps_ktc.svg

    python -c 'import os; print("\nGenerated dependency graph(s), as .svg files."); print("The graph(s) reside in the \"" + os.path.join("{toxinidir}", "{env:PYDOER_GRAPHS:pydoer-graphs}") + "\" directory and you can now view them ie in your browser.\n")'
